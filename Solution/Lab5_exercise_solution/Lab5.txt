Conda uses environments to load different sets of Python packages
type conda env list to see the environments availible.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/03/02 09:26:04 INFO SparkContext: Running Spark version 3.2.1
22/03/02 09:26:04 WARN NativeCodeLoader: Unable to load native-_hadoop library for your platform... using builtin-java classes where applicable
22/03/02 09:26:05 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
22/03/02 09:26:05 INFO ResourceUtils: ==============================================================
22/03/02 09:26:05 INFO ResourceUtils: No custom resources configured for spark.driver.
22/03/02 09:26:05 INFO ResourceUtils: ==============================================================
22/03/02 09:26:05 INFO SparkContext: Submitted application: Lab 3 Exercise
22/03/02 09:26:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/03/02 09:26:05 INFO ResourceProfile: Limiting resource is cpu
22/03/02 09:26:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/03/02 09:26:05 INFO SecurityManager: Changing view acls to: your_username
22/03/02 09:26:05 INFO SecurityManager: Changing modify acls to: your_username
22/03/02 09:26:05 INFO SecurityManager: Changing view acls groups to: 
22/03/02 09:26:05 INFO SecurityManager: Changing modify acls groups to: 
22/03/02 09:26:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(your_username); groups with view permissions: Set(); users  with modify permissions: Set(your_username); groups with modify permissions: Set()
22/03/02 09:26:07 INFO Utils: Successfully started service 'sparkDriver' on port 39201.
22/03/02 09:26:07 INFO SparkEnv: Registering MapOutputTracker
22/03/02 09:26:07 INFO SparkEnv: Registering BlockManagerMaster
22/03/02 09:26:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/03/02 09:26:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/03/02 09:26:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/03/02 09:26:07 INFO DiskBlockManager: Created local directory at /mnt/fastdata/your_username/blockmgr-117e0c6d-8aed-45d5-82b0-70df16b261b0
22/03/02 09:26:07 INFO MemoryStore: MemoryStore started with capacity 408.9 MiB
22/03/02 09:26:07 INFO SparkEnv: Registering OutputCommitCoordinator
22/03/02 09:26:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/03/02 09:26:08 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sharc-node174.shef.ac.uk:4040
22/03/02 09:26:08 INFO Executor: Starting executor ID driver on host sharc-node174.shef.ac.uk
22/03/02 09:26:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38366.
22/03/02 09:26:09 INFO NettyBlockTransferService: Server created on sharc-node174.shef.ac.uk:38366
22/03/02 09:26:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/03/02 09:26:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sharc-node174.shef.ac.uk, 38366, None)
22/03/02 09:26:09 INFO BlockManagerMasterEndpoint: Registering block manager sharc-node174.shef.ac.uk:38366 with 408.9 MiB RAM, BlockManagerId(driver, sharc-node174.shef.ac.uk, 38366, None)
22/03/02 09:26:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sharc-node174.shef.ac.uk, 38366, None)
22/03/02 09:26:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sharc-node174.shef.ac.uk, 38366, None)
/home/your_username/.conda/envs/myspark/lib/python3.6/site-packages/pyspark/python/lib/pyspark.zip/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.
  FutureWarning
22/03/02 09:26:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/03/02 09:26:11 INFO SharedState: Warehouse path is 'file:/data/your_username/ScalableML/HPC/spark-warehouse'.
22/03/02 09:26:19 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
+--------------------+------+
|            features|labels|
+--------------------+------+
|(57,[54,55,56],[1...|   0.0|
|(57,[54,55,56],[1...|   0.0|
|(57,[54,55,56],[1...|   0.0|
|(57,[54,55,56],[1...|   0.0|
|(57,[54,55,56],[1...|   0.0|
+--------------------+------+
only showing top 5 rows

Accuracy for best dt model = 0.912414 
{
    "cacheNodeIds": false,
    "checkpointInterval": 10,
    "featuresCol": "features",
    "impurity": "entropy",
    "labelCol": "labels",
    "leafCol": "",
    "maxBins": 100,
    "maxDepth": 10,
    "maxMemoryInMB": 256,
    "minInfoGain": 0.0,
    "minInstancesPerNode": 1,
    "minWeightFractionPerNode": 0.0,
    "predictionCol": "prediction",
    "probabilityCol": "probability",
    "rawPredictionCol": "rawPrediction",
    "seed": 956191873026065186
}
22/03/02 09:31:44 WARN BlockManager: Asked to remove block broadcast_6246_piece0, which does not exist
22/03/02 09:31:44 WARN BlockManager: Asked to remove block broadcast_6246, which does not exist
22/03/02 09:46:45 WARN BlockManager: Asked to remove block broadcast_23790_piece0, which does not exist
22/03/02 09:46:45 WARN BlockManager: Asked to remove block broadcast_23790, which does not exist
22/03/02 09:47:07 WARN BlockManager: Asked to remove block broadcast_24209_piece0, which does not exist
22/03/02 09:47:07 WARN BlockManager: Asked to remove block broadcast_24209, which does not exist
Accuracy for best rf model = 0.937548 
{
    "bootstrap": true,
    "cacheNodeIds": false,
    "checkpointInterval": 10,
    "featureSubsetStrategy": "sqrt",
    "featuresCol": "features",
    "impurity": "gini",
    "labelCol": "labels",
    "leafCol": "",
    "maxBins": 20,
    "maxDepth": 10,
    "maxMemoryInMB": 256,
    "minInfoGain": 0.0,
    "minInstancesPerNode": 1,
    "minWeightFractionPerNode": 0.0,
    "numTrees": 10,
    "predictionCol": "prediction",
    "probabilityCol": "probability",
    "rawPredictionCol": "rawPrediction",
    "seed": 42,
    "subsamplingRate": 0.9
}
                 feature  importance
10               alcohol    0.362308
5    free sulfur dioxide    0.126526
6   total sulfur dioxide    0.123094
1       volatile acidity    0.113669
7                density    0.086806
3         residual sugar    0.056249
2            citric acid    0.042743
0          fixed acidity    0.029582
4              chlorides    0.025092
8                     pH    0.024460
9              sulphates    0.009472
